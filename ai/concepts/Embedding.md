# Embedding (임베딩)

## 📌 개념 (Concept)
사람이 이해하는 ID(숫자, 문자열)를 **컴퓨터(AI)가 이해할 수 있는 벡터(숫자들의 나열)**로 바꾸는 기술입니다.

- **핵심 역할**: **"의미(Meaning)를 숫자로 표현"**
- **비유**:
    - `User ID: 1` -> 컴퓨터는 이게 누군지 모름.
    - `Embedding`: `[0.1, 0.9, -0.5]` -> "아, 이 사람은 액션(0.9)을 좋아하고 로맨스(-0.5)는 싫어하는구나!"

## ⚙️ 원리
- 처음에는 랜덤한 숫자로 채워져 있습니다.
- 학습(Training)을 하면서, 비슷한 성향의 유저나 비슷한 장르의 영화끼리는 **비슷한 숫자(벡터)**를 갖도록 값이 조정됩니다.
- 이를 통해 **"희소한(Sparse)"** 데이터(수만 명의 유저)를 **"밀집된(Dense)"** 벡터(32~64개 숫자)로 압축하여 표현합니다.

## 💡 추천 시스템에서의 활용
- 모든 딥러닝 추천 모델(MF, NCF, SASRec 등)의 **가장 첫 번째 단계**입니다.
- 유저와 아이템을 임베딩으로 바꿔야 신경망에 넣고 계산할 수 있습니다.

## 💻 코드 예시 (PyTorch)
```python
# 100명의 유저를 각각 32개의 숫자로 표현하겠다
embedding_layer = nn.Embedding(num_embeddings=100, embedding_dim=32)

# 1번 유저의 벡터 가져오기
user_vector = embedding_layer(torch.tensor([1])) 
# 결과: tensor([[-0.123, 0.456, ...]]) (32개 숫자)
```
