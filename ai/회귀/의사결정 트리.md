# 의사결정 트리(Decision Tree) 정리

## 핵심 정의

의사결정 트리는 데이터 요소를 분류하기 위한 **순서도 형태의 알고리즘**으로, 각 내부 노드는 테스트, 각 분기는 테스트 결과, 각 리프 노드는 클래스 할당에 해당합니다.subtitle-3.txt​

## 구조

- **내부 노드(Internal Node)**: 특징에 대한 테스트subtitle-3.txt​
    
- **분기(Branch)**: 테스트 결과subtitle-3.txt​
    
- **리프 노드(Leaf/Terminal Node)**: 최종 클래스 할당subtitle-3.txt​
    

## 실전 예시: 약물 처방

## 문제 설정

동일한 질병을 앓는 환자들이 약물 A 또는 약물 B에 반응했던 데이터로 미래 환자에게 적합한 약물 예측subtitle-3.txt​

**특징**: 연령, 성별, 혈압, 콜레스테롤subtitle-3.txt​  
**목표**: 약물 A 또는 Bsubtitle-3.txt​

## 결정 트리 예시

1. **연령**: 중년 → 약물 Bsubtitle-3.txt​
    
2. **젊은층**: 남성 → 약물 B / 여성 → 콜레스테롤 확인subtitle-3.txt​
    
3. **노년층**: 콜레스테롤 정상 → 약물 B / 높음 → 약물 Asubtitle-3.txt​
    

## 훈련 과정

## 5단계 프로세스

1. **시작**: 시드 노드와 레이블이 지정된 훈련 데이터subtitle-3.txt​
    
2. **특징 선택**: 분할 기준에 따라 데이터를 가장 잘 분할하는 특징 찾기subtitle-3.txt​
    
3. **노드 훈련**: 할당된 데이터로 노드 학습subtitle-3.txt​
    
4. **재귀 반복**: 각 특징을 한 번만 사용하여 새 노드마다 반복subtitle-3.txt​
    
5. **중지**: 중지 기준 충족 시 트리 성장 멈춤subtitle-3.txt​
    

## 중지 기준 (조기 가지치기)

- 최대 트리 깊이 도달subtitle-3.txt​
    
- 노드의 최소 데이터 포인트 수 초과subtitle-3.txt​
    
- 리프의 최소 샘플 수 초과subtitle-3.txt​
    
- 최대 리프 노드 수 도달subtitle-3.txt​
    

## 가지치기(Pruning)

## 필요성

- **과적합 방지**: 트리가 너무 복잡하면 훈련 데이터 암기subtitle-3.txt​
    
- **노이즈 제거**: 클래스와 특징이 너무 많으면 관련 없는 세부사항 포착subtitle-3.txt​
    

## 이점

- 모델 단순화 및 일반화subtitle-3.txt​
    
- 더 간결하고 이해하기 쉬움subtitle-3.txt​
    
- 예측 정확도 향상subtitle-3.txt​
    

## 분할 기준

## 1. 엔트로피 (Entropy)

**정의**: 데이터셋의 무작위성 또는 불확실성 척도subtitle-3.txt​

**공식**:

Entropy=−pAlog⁡2(pA)−pBlog⁡2(pB)\text{Entropy} = -p_A \log_2(p_A) - p_B \log_2(p_B)Entropy=−pAlog2(pA)−pBlog2(pB)

- pAp_ApA, pBp_BpB: 각 클래스의 비율subtitle-3.txt​
    

**특징**:

- 클래스가 완전히 동질적 → 엔트로피 = 0subtitle-3.txt​
    
- 클래스가 균등하게 나뉨 → 엔트로피 = 1subtitle-3.txt​
    
- **목표**: 엔트로피가 가장 작은 트리 찾기subtitle-3.txt​
    

## 2. 정보 이득 (Information Gain)

**공식**:

Information Gain=Entropy(before)−Weighted Entropy(after)\text{Information Gain} = \text{Entropy(before)} - \text{Weighted Entropy(after)}Information Gain=Entropy(before)−Weighted Entropy(after)

**의미**: 특징으로 분할 후 엔트로피 감소량subtitle-3.txt​

**관계**: 엔트로피 감소 = 정보 이득 증가 = 확실성 증가subtitle-3.txt​

**예시**: 콜레스테롤로 분할 시 정보 이득 = 0.042subtitle-3.txt​

## 3. 지니 불순물 (Gini Impurity)

정보 이득과 함께 사용되는 또 다른 일반적인 분할 측정 지표subtitle-3.txt​

## 분할 예시 비교

## 콜레스테롤로 분할

- 높음 노드: 약물 B 확신 불가subtitle-3.txt​
    
- 정상 노드: 약물 A/B 판단 불충분subtitle-3.txt​
    
- **결론**: 최적 특징 아님subtitle-3.txt​
    

## 성별로 분할

- 여성: 대부분 약물 Bsubtitle-3.txt​
    
- 남성: 약물 A/B 불명확 → 콜레스테롤로 재분할subtitle-3.txt​
    
- **결과**: 순수한 말기 노드 생성subtitle-3.txt​
    

## 의사결정 트리의 장점

**해석 가능성**: 시각화 가능하여 의사결정 방식을 정확히 파악 가능subtitle-3.txt​

**특징 중요도**: 분할 순서를 통해 각 특징의 예측 가능성 파악subtitle-3.txt​

**직관적**: 순서도 형태로 이해하기 쉬움subtitle-3.txt​

## 핵심 요약

- 의사결정 트리는 **재귀 파티셔닝**으로 데이터 분류subtitle-3.txt​
    
- **정보 이득**이 가장 큰 특징을 선택하여 분할subtitle-3.txt​
    
- **가지치기**로 과적합 방지 및 정확도 향상subtitle-3.txt​
    
- **엔트로피**와 **정보 이득**으로 최적 분할 결정subtitle-3.txt​
    
- 시각화 가능하여 해석이 용이하고 특징 중요도 파악 가능subtitle-3.txt​
    

1. [https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/3354832/62b04b1b-63df-438c-9133-f63907246bba/subtitle-3.txt](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/3354832/62b04b1b-63df-438c-9133-f63907246bba/subtitle-3.txt)