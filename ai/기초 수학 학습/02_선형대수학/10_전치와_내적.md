# 10 전치와 내적: 벡터와 행렬의 숨겨진 의미

## 1. 전치(Transpose): 행과 열의 자리바꿈

**전치(Transpose)** 는 [[09_벡터와_행렬|행렬]]의 행과 열을 서로 바꾸는 연산입니다. 마치 행렬을 대각선을 기준으로 뒤집는 것과 같습니다.

- **표기**: 행렬 $A$의 전치는 $A^T$ 또는 $A'$ 로 표기합니다.

**예시:**
$2 	imes 3$ 행렬 $$ A = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix} $$

$A$의 전치 행렬은 $3 	imes 2$ 행렬이 됩니다.
$$ A^T = \begin{bmatrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{bmatrix} $$

### 전치의 특징

1.  $(A^T)^T = A$: 전치된 행렬을 다시 전치하면 원래 행렬로 돌아옵니다.
2.  $(A + B)^T = A^T + B^T$: 합의 전치는 전치의 합과 같습니다.
3.  $(cA)^T = cA^T$: 스칼라 곱의 전치는 스칼라를 먼저 곱하고 전치한 것과 같습니다.
4.  $(AB)^T = B^T A^T$: 곱의 전치는 순서가 바뀐 전치의 곱과 같습니다. (매우 중요!)

### AI에서의 활용

- **차원 맞추기**: [[09_벡터와_행렬#^행렬의 기본 연산|행렬 곱셈]]을 할 때, 두 행렬의 차원을 맞추기 위해 전치를 사용합니다.
- **데이터 재구성**: 데이터를 특정 형태로 재구성할 때 유용합니다.
- **내적 계산**: 벡터의 내적을 행렬 곱셈 형태로 표현할 때 사용됩니다.

## 2. 내적(Inner Product 또는 Dot Product): 벡터 간의 유사도와 투영

내적(Inner Product)은 두 벡터를 곱하여 하나의 [[09_벡터와_행렬#^스칼라 곱 (Scalar Multiplication)|스칼라]](숫자) 값을 얻는 연산입니다. 내적은 두 벡터가 얼마나 같은 방향을 향하고 있는지, 즉 얼마나 '유사한지'를 측정하는 데 사용됩니다.

- **표기**: 두 벡터 $\vec{a}$와 $\vec{b}$의 내적은 $\vec{a} \cdot \vec{b}$ 또는 $\vec{a}^T \vec{b}$ 로 표기합니다.

### 내적의 계산

두 벡터 $\vec{a} = [a_1, a_2, \dots, a_n]$ 와 $\vec{b} = [b_1, b_2, \dots, b_n]$ 의 내적은 각 요소끼리 곱한 후 모두 더하는 방식으로 계산합니다.

> $$\vec{a} \cdot \vec{b} = a_1 b_1 + a_2 b_2 + \dots + a_n b_n$$ 

**예시:**
$\vec{a} = [1, 2]$
$\vec{b} = [3, 4]$

> $$\vec{a} \cdot \vec{b} = (1)(3) + (2)(4) = 3 + 8 = 11$$ 

### 내적의 기하학적 의미 (매우 중요!)

내적은 단순히 숫자를 계산하는 것을 넘어, 두 벡터의 기하학적인 관계를 알려줍니다.

> $$\vec{a} \cdot \vec{b} = \|\vec{a}\| \|\vec{b}\| \cos(\theta)$$ 

여기서 $\|\vec{a}\|$
는 벡터 $\vec{a}$의 크기(길이), $\|\vec{b}\|$
는 벡터 $\vec{b}$의 크기, $\theta$
는 두 벡터 사이의 각도입니다.

이 공식을 통해 우리는 다음을 알 수 있습니다.

-   **유사도 측정**: $\cos(\theta)$
 값은 두 벡터의 방향이 얼마나 유사한지를 나타냅니다.
    -   $\theta = 0^\circ$ (같은 방향): $\cos(0^\circ) = 1$. 내적 값이 최대가 됩니다. (두 벡터가 매우 유사)
    -   $\theta = 90^\circ$ (직교, 수직): $\cos(90^\circ) = 0$. 내적 값이 $0$이 됩니다. (두 벡터가 전혀 관련 없음)
    -   $\theta = 180^\circ$ (반대 방향): $\cos(180^\circ) = -1$. 내적 값이 최소가 됩니다. (두 벡터가 매우 반대)
-   **투영 (Projection)**: 한 벡터가 다른 벡터 위에 얼마나 '그림자'를 드리우는지를 나타냅니다. $(\vec{a} \cdot \vec{b}) / \|\vec{b}\|$
 는 벡터 $\vec{a}$를 벡터 $\vec{b}$ 위에 투영한 길이입니다.

### AI에서의 활용

-   **유사도 측정**: 자연어 처리(NLP)에서 단어나 문서의 의미를 벡터로 표현한 후, 내적(또는 코사인 유사도)을 통해 두 단어나 문서가 얼마나 유사한지 측정합니다.
-   **추천 시스템**: 사용자의 선호도 벡터와 아이템의 특징 벡터를 내적하여 사용자에게 적합한 아이템을 추천합니다.
-   **신경망**: 신경망의 각 뉴런에서 입력 벡터와 가중치 벡터의 내적을 계산하여 다음 층으로 전달할 값을 결정합니다.

## 확인 문제

1.  행렬 $$ B = \begin{bmatrix} 1 & 2 \\ 3 & 4 \\ 5 & 6 \end{bmatrix} $$ 의 전치 $B^T$ 를 구해보세요.
2.  두 벡터 $\vec{v} = [2, -1, 3]$ 와 $\vec{w} = [1, 4, 0]$ 의 내적 $\vec{v} \cdot \vec{w}$ 를 계산해보세요.
3.  두 벡터 $\vec{p} = [1, 0]$ 와 $\vec{q} = [0, 1]$ 의 내적은 얼마일까요? 이 결과가 기하학적으로 무엇을 의미하는지 설명해보세요.

---

*전치와 내적은 AI에서 데이터를 다루고, 벡터 간의 관계를 이해하는 데 필수적인 개념입니다. 특히 내적의 기하학적 의미를 잘 이해하는 것이 중요합니다.*