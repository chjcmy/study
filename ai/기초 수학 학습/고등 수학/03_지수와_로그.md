# 03 지수와 로그: 성장, 스케일, 그리고 정보의 언어

## 1. 지수와 로그: 동전의 양면 같은 관계

지수(Exponent)와 로그(Logarithm)는 서로 뗄 수 없는 **역함수(Inverse Function)** 관계입니다. 이 둘은 AI에서 성장과 스케일, 확률과 정보를 다루는 데 핵심적인 언어로 사용됩니다.

-   **지수**: $y = b^x$ -> "$b$를 $x$번 곱하면 $y$가 된다." (어떤 수를 거듭 곱했을 때의 **결과**에 관심)
-   **로그**: $x = \log_b(y)$ -> "$b$를 몇 번 곱해야 $y$가 될까?" (결과를 만들기 위해 거듭 곱한 **횟수**에 관심)

그래프에서 $y = e^x$와 $y = \ln(x)$는 $y=x$ 직선에 대해 완벽한 대칭을 이룹니다. 이는 둘의 역함수 관계를 시각적으로 보여줍니다.

## 2. 지수 (Exponents): 성장의 법칙

지수는 곱셈의 반복을 간결하게 표현하며, 기하급수적인 성장 또는 감소를 모델링합니다.

### 핵심 지수 법칙

-   $a^m a^n = a^{m+n}$
-   $a^m / a^n = a^{m-n}$
-   $(a^m)^n = a^{mn}$
-   $a^0 = 1$
-   $a^{-n} = 1 / a^n$

### AI와의 연결점

-   **활성화 함수 (Activation Functions)**: 신경망은 입력 신호를 받아 다음 뉴런으로 보낼지 말지를 결정하기 위해 활성화 함수를 사용합니다. 지수 함수는 여러 중요한 활성화 함수의 기초가 됩니다.
    -   **시그모이드 (Sigmoid)**: $\frac{1}{1 + e^{-x}}$. $e^x$를 이용하여 출력을 0과 1 사이로 만들어 확률처럼 해석할 수 있게 합니다.
    -   **소프트맥스 (Softmax)**: $P(i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}$. 여러 개의 출력 값을 합이 1이 되는 확률 분포로 변환하여, 다중 클래스 분류 문제에서 각 클래스에 속할 확률을 나타내는 데 사용됩니다.
-   **확률 모델링**: 사건의 발생 확률을 모델링할 때 지수 함수가 자주 사용됩니다. (예: 포아송 분포)

## 3. 로그 (Logarithms): 스케일의 법칙

로그는 매우 큰 숫자 범위를 다루기 쉬운 작은 범위로 압축하고, 복잡한 곱셈을 덧셈으로 변환하는 마법 같은 도구입니다.

### 핵심 로그 성질

-   $\log(xy) = \log(x) + \log(y)$ (곱셈 -> 덧셈)
-   $\log(x/y) = \log(x) - \log(y)$ (나눗셈 -> 뺄셈)
-   $\log(x^p) = p \log(x)$ (지수 -> 곱셈)

### AI와의 연결점

-   **계산의 안정성 및 효율성 (Log-Likelihood)**: 모델이 예측한 여러 사건의 전체 확률은 각 사건의 확률을 모두 곱한 값입니다. 수많은 0과 1 사이의 확률을 곱하면 컴퓨터가 처리하기 어려운 매우 작은 수가 되어 계산 오류(numerical underflow)가 발생할 수 있습니다. 여기에 로그를 취하면 **곱셈이 덧셈으로 바뀌어($\sum \log(P_i)$)** 계산이 매우 안정적이고 간단해집니다. 이는 최대 우도 추정(MLE)의 핵심입니다.

-   **손실 함수 (Loss Functions)**: 모델이 얼마나 틀렸는지를 측정하는 손실 함수에 로그가 핵심적으로 사용됩니다.
    -   **교차 엔트로피 (Cross-Entropy)**: $Loss = - \sum y_{\text{true}} \log(y_{	ext{pred}})$. 분류 문제의 표준 손실 함수입니다. 모델이 정답($y_{	ext{true}}=1$)에 대해 0에 가까운 확률($y_{	ext{pred}} \to 0$)을 예측하면, $\log(y_{	ext{pred}})$는 음의 무한대로 발산합니다. 이는 모델에게 **자신 있게 틀리는 것에 대해 엄청난 페널티**를 부여하여, 모델이 더 정확한 예측을 하도록 강하게 유도합니다.

-   **정보 이론 (Information Theory)**: 정보의 양을 나타내는 엔트로피(Entropy)는 로그를 사용하여 정의됩니다. 로그는 놀라움의 정도, 즉 정보의 가치를 측정하는 척도입니다.

## 4. 자연 상수 $e$와 자연로그 $\ln$

수많은 밑 중에서 왜 하필 $e$ (약 2.718)를 사용하는 자연로그가 AI에서 가장 중요할까요? 그 이유는 함수 $y = e^x$가 **미분해도 자기 자신($y' = e^x$)이 되는 유일한 함수**이기 때문입니다. 이 독특한 성질 덕분에 $e$는 미적분학에서 '성장'과 '변화'를 설명하는 가장 자연스러운 언어가 되며, 이는 AI 모델의 학습(미분을 통한 최적화) 과정과 깊이 연결됩니다.

---

*지수는 성장을, 로그는 그 성장을 이해하기 쉬운 스케일로 변환하는 도구입니다. AI에서 확률을 다루고, 모델의 오차를 정의하며, 계산 과정을 안정적으로 만드는 데 있어 지수와 로그의 상호보완적인 관계를 이해하는 것은 매우 중요합니다.*