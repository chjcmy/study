# 02 미분 (Differentiation): AI 학습의 엔진

## 1. 미분의 핵심 아이디어: 순간 변화율과 기울기

미분은 **'어떤 함수의 특정 지점에서의 순간적인 변화율'** 또는 **'그래프의 한 점에서의 접선의 기울기'** 를 구하는 과정입니다.

-   **기울기(Gradient)**: 함수가 특정 지점에서 얼마나 가파르게 변하는지, 그리고 증가하는지 감소하는지를 알려주는 값입니다.
    -   기울기 > 0: 함수가 증가하는 중
    -   기울기 < 0: 함수가 감소하는 중
    -   기울기 = 0: 함수 값의 변화가 없는 지점 (극점 또는 안장점)
-   **도함수(Derivative)**: 원래 함수의 각 지점에서의 기울기 값을 알려주는 새로운 함수입니다. $f(x)$의 도함수를 $f'(x)$ 또는 $\frac{df}{dx}$로 표기합니다.

## 2. AI 모델 학습의 핵심: 경사 하강법 (Gradient Descent)

AI 모델, 특히 딥러닝 모델을 학습시키는 과정은 **손실 함수(Loss Function)의 값을 최소로 만드는 최적의 파라미터(가중치)를 찾는 것**입니다. 이는 거대한 산맥에서 가장 낮은 골짜기를 찾아 내려가는 과정과 같습니다.

1.  **손실 함수(Loss Function)**: 모델의 예측이 정답과 얼마나 다른지를 나타내는 함수입니다. 이 함수의 값이 작을수록 모델의 성능이 좋은 것입니다. 이 함수를 우리가 탐험할 '지형'이라고 상상해봅시다.
2.  **파라미터(Parameters)**: 모델의 예측을 결정하는 수많은 가중치와 편향입니다. 이는 지형 위에서 우리의 '위치'를 나타냅니다.
3.  **목표**: 손실 함수라는 지형의 가장 낮은 지점(최솟값)을 찾는 것입니다.

이때, 어느 방향으로 가야 가장 빨리 내려갈 수 있을까요? 바로 **미분**을 통해 현재 위치의 **기울기(Gradient)**를 계산합니다.

-   **경사 하강법 (Gradient Descent)**:
    1.  현재 위치(파라미터)에서 손실 함수의 기울기(Gradient)를 계산합니다.
    2.  기울기는 가장 가파른 **오르막** 방향을 가리킵니다.
    3.  따라서 우리는 **기울기의 반대 방향**으로 아주 조금씩 이동합니다.
    4.  이 과정을 손실이 더 이상 줄어들지 않을 때까지 반복합니다.

> **업데이트 규칙**:
> $$ \theta_{\text{new}} = \theta_{\text{old}} - \eta \nabla L(\theta_{\text{old}}) $$
> - $\theta$: 모델의 파라미터
> - $\eta$: **학습률(Learning Rate)**. 한 번에 얼마나 크게 이동할지를 결정하는 보폭.
> - $\nabla L$: 손실 함수 $L$의 기울기(Gradient).

## 3. 복잡한 모델을 위한 미분: 역전파와 연쇄 법칙

신경망처럼 수많은 함수가 중첩된 복잡한 모델의 기울기는 어떻게 효율적으로 계산할까요? 이때 **연쇄 법칙(Chain Rule)**을 사용하는 **역전파(Backpropagation)** 알고리즘이 사용됩니다.

-   **연쇄 법칙 (Chain Rule)**: 합성 함수 $y = f(g(x))$의 도함수는 각 함수의 도함수의 곱으로 표현됩니다.
    $$ \frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dx} \quad (\text{단, } u=g(x)) $$
-   **역전파 (Backpropagation)**: 신경망의 최종 출력(손실)에서부터 입력 방향으로, 연쇄 법칙을 연쇄적으로 적용하여 각 파라미터에 대한 기울기를 효율적으로 계산하는 알고리즘입니다. 이는 모델의 모든 파라미터가 손실에 얼마나 기여했는지를 계산하여, 각자 책임져야 할 만큼 업데이트되도록 만듭니다.

결론적으로, **미분은 모델이 무엇을 잘못했는지(손실)를 파악하고, 어느 방향으로 개선되어야 하는지(기울기) 알려주는 핵심적인 역할을 합니다.**

---

## 4. 확인 문제 (Practice Problems)

1.  **기울기 해석**: 어떤 손실 함수의 특정 지점에서 계산한 기울기가 음수(-)였습니다. 파라미터를 업데이트할 때, 해당 파라미터의 값을 증가시켜야 할까요, 감소시켜야 할까요? (힌트: 기울기의 반대 방향)

2.  **학습률의 역할**: 경사 하강법에서 학습률($\eta$)을 너무 크게 설정하면 어떤 문제가 발생할 수 있을까요? 반대로 너무 작게 설정하면 어떤 문제가 있을까요?

3.  **역전파**: 수십 개의 층(layer)으로 이루어진 매우 깊은 신경망(deep neural network)의 모든 파라미터에 대한 기울기를 효율적으로 계산하기 위해 사용되는 핵심적인 미분 법칙은 무엇인가요?

---
*미분은 AI 모델을 '학습'시키는 엔진입니다. 손실 함수의 기울기를 계산하여 모델이 나아갈 방향을 제시함으로써, 복잡한 데이터 속에서 패턴을 학습하는 것을 가능하게 합니다.*