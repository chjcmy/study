# 15 최대 사후 확률 (MAP): 사전 지식을 활용한 더 현명한 추정

## 1. MLE의 한계와 사전 지식의 중요성

이전 학습에서 우리는 [[14_최대_우도_추정_(MLE)|최대 우도 추정(MLE)]]을 통해 주어진 데이터를 가장 잘 설명하는 모델 파라미터를 찾는 방법을 배웠습니다. MLE는 데이터 자체의 정보(우도)만을 활용하여 파라미터를 추정합니다.

하지만 때로는 데이터 외에 우리가 이미 알고 있는 **'사전 지식(Prior Knowledge)'** 이 있을 수 있습니다. 예를 들어, 동전 던지기 실험을 3번 했는데 모두 앞면이 나왔다고 가정해봅시다. MLE로 추정하면 앞면이 나올 확률 $p$는 1이 됩니다. 하지만 우리는 대부분의 동전이 공정하다는 사전 지식을 가지고 있습니다. 이 사전 지식을 무시하고 $p=1$이라고 단정하는 것이 항상 최선일까요?

**최대 사후 확률(Maximum a posteriori estimation, MAP)** 은 바로 이 사전 지식을 파라미터 추정 과정에 통합하는 방법입니다.

## 2. 베이즈 정리 다시 보기: MAP의 핵심

MAP는 **[[고등 수학/05_확률과_통계_심화/02_조건부_확률과_독립성#^베이즈 정리 (Bayes' Theorem)|베이즈 정리(Bayes' Theorem)]]** 에 기반을 둡니다. 베이즈 정리는 다음과 같습니다.

> $$P(\theta | \text{데이터}) = \frac{P(\text{데이터} | \theta) P(\theta)}{P(\text{데이터})}$$ 

여기서 각 항의 의미를 파라미터 추정 관점에서 다시 살펴봅시다.

-   **$P(\theta | \text{데이터})$ (사후 확률, Posterior Probability)**: 우리가 최대화하고자 하는 값입니다. 데이터를 관찰한 후, 파라미터 $\theta$가 특정 값일 확률입니다. 즉, **데이터를 보고 업데이트된 파라미터 $\theta$에 대한 믿음**입니다.
-   **$P(\text{데이터} | \theta)$ ([[14_최대_우도_추정_(MLE)#^우도(Likelihood)|우도, Likelihood]])**: MLE에서 최대화했던 바로 그 우도입니다. 파라미터 $\theta$가 주어졌을 때, 현재 데이터를 관찰할 확률입니다.
-   **$P(\theta)$ (사전 확률, Prior Probability)**: **MAP의 핵심이자 MLE와의 차이점입니다.** 데이터를 관찰하기 전, 파라미터 $\theta$에 대한 우리의 사전 믿음 또는 지식입니다. (예: 동전은 대부분 공정할 것이다.)
-   **$P(\text{데이터})$ (증거, Evidence)**: 데이터를 관찰할 전체 확률입니다. 이 값은 파라미터 $\theta$에 의존하지 않으므로, $P(\theta | \text{데이터})$를 최대화하는 $\theta$를 찾을 때는 상수로 취급하여 무시할 수 있습니다.

따라서 MAP는 $P(\theta | \text{데이터})$를 최대화하는 $\theta$를 찾는 것이며, 이는 $P(\text{데이터} | \theta) P(\theta)$를 최대화하는 것과 같습니다.

> **MAP는 (우도 $\times$ 사전 확률)을 최대로 만드는 파라미터를 찾습니다.**

## 3. MAP vs. MLE: 무엇이 다를까요?

-   **MLE**: $\underset{\theta}{\text{argmax}} P(\text{데이터} | \theta)$ (데이터의 우도만을 고려)
-   **MAP**: $\underset{\theta}{\text{argmax}} P(\text{데이터} | \theta) P(\theta)$ (데이터의 우도와 파라미터의 사전 확률을 모두 고려)

**주요 차이점**: MAP는 파라미터에 대한 사전 확률 $P(\theta)$를 포함합니다. 이 사전 확률은 우리가 모델 파라미터에 대해 가지고 있는 '편향' 또는 '선호도'를 나타냅니다.

-   **사전 확률의 영향**: 만약 사전 확률 $P(\theta)$가 모든 $\theta$에 대해 동일하다면 (즉, 어떤 파라미터 값도 특별히 선호하지 않는다면), MAP는 MLE와 동일해집니다.
-   **데이터 양의 영향**: 데이터의 양이 매우 많아지면, 우도 $P(\text{데이터} | \theta)$의 영향력이 사전 확률 $P(\theta)$보다 훨씬 커지게 됩니다. 이 경우 MAP와 MLE의 결과는 거의 같아집니다. 사전 지식보다는 데이터 자체가 더 강력한 증거가 되기 때문입니다.

## 4. 예시: 동전 던지기 (사전 지식 포함)

동전을 3번 던져 모두 앞면이 나왔습니다. (데이터: H, H, H)

-   **MLE**: $p=1$ (앞면이 나올 확률이 1인 동전이라고 추정)

-   **MAP**: 여기에 사전 지식을 추가해봅시다. "대부분의 동전은 앞면이 나올 확률이 0.5에 가깝다"는 사전 믿음($P(p)$)을 가지고 있다고 가정합니다. 예를 들어, $p$가 0.5 근처에 있을 확률이 높고, 0이나 1에 가까울수록 확률이 낮아지는 베타 분포(Beta distribution)를 사전 분포로 사용할 수 있습니다.

    이 경우, MAP는 $P(\text{데이터} | p) P(p)$를 최대화합니다. 비록 데이터는 $p=1$을 가리키지만, 사전 분포가 $p=0.5$를 강하게 선호한다면, MAP 추정치는 $p=1$보다는 $0.5$에 더 가까운 값(예: 0.7~0.8)이 될 수 있습니다. 이는 적은 데이터로 인한 과도한 추정을 방지하는 효과가 있습니다.

## 5. MAP와 AI: 정규화(Regularization) 효과

MAP는 머신러닝에서 **정규화(Regularization)** 의 한 형태로 볼 수 있습니다. 사전 확률 $P(\theta)$는 모델 파라미터가 너무 극단적인 값(예: 너무 크거나 너무 작은 가중치)을 가지는 것을 방지하여, 모델이 과적합(Overfitting)되는 것을 막는 역할을 합니다.

-   **베이즈 머신러닝**: MAP는 베이즈 통계학의 핵심 개념이며, 베이즈 선형 회귀, 베이즈 신경망 등 베이즈 머신러닝 모델의 기초가 됩니다.

## 확인 문제

1.  MLE와 MAP의 가장 큰 차이점은 무엇인가요?
2.  사전 확률 $P(\theta)$가 모든 $\theta$에 대해 동일할 때, MAP는 어떤 추정 방법과 같아지나요?
3.  데이터의 양이 매우 많을 때, MLE와 MAP의 결과는 어떻게 될까요?

---

*MAP는 사전 지식을 활용하여 더 견고하고 현실적인 파라미터 추정을 가능하게 합니다. 특히 데이터가 부족하거나 노이즈가 많을 때, 사전 지식은 모델의 성능을 향상시키는 데 큰 도움을 줄 수 있습니다.*
