# 순전파 (Forward Propagation)

순전파는 인공 신경망에서 입력 데이터가 입력층에서부터 출력층까지 순차적으로 전달되며 각 층에서 계산이 수행되는 과정을 의미합니다. 이 과정은 모델이 주어진 입력에 대해 어떤 예측값을 만들어내는지를 결정합니다.

## 순전파의 과정

신경망의 각 뉴런(노드)은 이전 층의 출력값과 **가중치(Weight)**의 곱셈, 그리고 **편향(Bias)**의 덧셈으로 구성된 **가중합(Weighted Sum)**을 계산합니다. 이후, 이 가중합은 **활성화 함수(Activation Function)**를 통과하여 최종 출력값을 생성합니다.

1.  **입력층 (Input Layer):**
    *   외부로부터 데이터를直接 받아들입니다.
    *   입력 데이터는 각 특성(feature)에 해당하는 값들의 벡터(vector) 형태입니다.

2.  **은닉층 (Hidden Layer):**
    *   입력층으로부터 데이터를 전달받습니다.
    *   각 뉴런에서는 다음의 계산이 수행됩니다.
        1.  **가중합(Weighted Sum) 계산:**
            *   이전 층 뉴런들의 출력값 `x`에 각각의 연결에 부여된 **가중치 `W`**를 곱한 후 모두 더합니다.
            *   여기에 **편향 `b`**를 더합니다.
            *   `Z = (x₁ * W₁) + (x₂ * W₂) + ... + (xₙ * Wₙ) + b`
        2.  **활성화 함수(Activation Function) 적용:**
            *   계산된 가중합 `Z`를 **활성화 함수 `f()`**에 입력하여 최종 출력값 `A`를 계산합니다.
            *   `A = f(Z)`
            *   활성화 함수는 비선형성을 추가하여 모델이 복잡한 패턴을 학습할 수 있도록 돕습니다 (예: ReLU, Sigmoid, Tanh).
    *   이 과정은 신경망의 모든 은닉층에서 반복됩니다. 한 층의 출력은 다음 층의 입력이 됩니다.

3.  **출력층 (Output Layer):**
    *   마지막 은닉층으로부터 값을 전달받아 최종 예측값을 출력합니다.
    *   출력층의 활성화 함수는 문제의 종류에 따라 달라집니다.
        *   **회귀 (Regression):** 주로 **선형 함수(Linear Function)**를 사용하여 연속적인 값을 예측합니다.
        *   **이진 분류 (Binary Classification):** **시그모이드(Sigmoid)** 함수를 사용하여 0과 1 사이의 확률 값을 출력합니다.
        *   **다중 클래스 분류 (Multi-class Classification):** **소프트맥스(Softmax)** 함수를 사용하여 각 클래스에 대한 확률을 출력하며, 모든 클래스의 확률 총합은 1이 됩니다.

## 순전파의 역할과 다음 단계

*   **예측값 생성:** 순전파는 현재 신경망의 가중치와 편향을 기반으로 입력 데이터에 대한 **예측값(Prediction)**을 생성하는 과정입니다.
*   **오차 계산의 기반:** 순전파를 통해 얻은 예측값은 **실제값(Ground Truth)**과 비교되어 **오차(Error) 또는 손실(Loss)**을 계산하는 데 사용됩니다.
*   **역전파의 시작점:** 계산된 오차는 모델을 학습시키기 위한 **역전파(Backpropagation)** 단계의 시작점이 됩니다. 역전파는 이 오차를 기반으로 각 가중치를 얼마나 수정해야 할지 결정합니다.

따라서 순전파는 신경망의 추론(Inference) 과정이자, 학습 과정의 첫 번째 단계라고 할 수 있습니다.

---
## 연관 문서
- 다음 단계: [[2. 오차]]

