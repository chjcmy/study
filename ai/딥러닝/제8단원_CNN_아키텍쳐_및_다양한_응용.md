# 제8단원: CNN 아키텍처 및 다양한 응용 완전판

7단원까지는 **CNN이 왜 필요하고, Conv/Pool/Flatten이 어떤 역할을 하는지**를 봤습니다.[file:5]  
이제는 그 블록들을 실제로 어떻게 쌓아 왔는지, 그리고 어떤 실전 문제에 적용해 볼 수 있는지를 정리합니다.[file:6]

---

## 1. CNN의 조상님: LeNet-5

CNN이 처음부터 지금처럼 복잡하지는 않았습니다.  
1998년, **얀 르쿤(Yann LeCun)**이 제안한 **LeNet-5**가 대표적인 시조새 모델입니다.[file:6]

- **등장 배경**  
  - 우체국에서 손글씨로 적힌 우편번호를 자동 인식하기 위해 개발.  
- **구조 요약**  
  - `Conv → Pool → Conv → Pool → Flatten → Dense`  
  - 합성곱과 풀링을 번갈아 쌓은 뒤, 마지막에 MLP(완전연결층)로 분류하는 구조입니다.[file:6]
- **이름의 의미**  
  - 주요 층이 5개라서 “LeNet-5”.

> 중요한 점은, 이 모델이 현대 CNN의 기본 패턴인  
> **“Conv 다음에 Pool을 둔다”**는 공식을 사실상 처음 정립했다는 것입니다.[file:6]

### 💡 개념 체크 Quiz 1

Q. 1998년에 제안되어 우편번호 인식에 사용되었고,  
'Conv-Pool' 반복 구조의 기틀을 마련한 초창기 CNN 모델은?  

A) ResNet  
B) LeNet-5  
C) Transformer  

👉 **정답: B**  
LeNet-5는 지금의 복잡한 CNN들(VGG, ResNet 등)의 할아버지 같은 존재입니다.[file:6]

---

## 2. 실전 프로젝트 (1): 패션 아이템 분류 – Fashion MNIST

숫자 MNIST로 감을 잡았다면, 다음 단계는 **옷(Fashion MNIST)**입니다.[file:6]

- **데이터 구성**  
  - 티셔츠, 바지, 코트, 운동화 등 10가지 패션 아이템.  
  - 크기: 28×28 흑백 이미지 (MNIST와 동일 크기).  
- **난이도 특징**  
  - 숫자보다 훨씬 헷갈립니다.  
  - 예: 셔츠 vs 코트, 샌들 vs 운동화처럼 모양이 비슷한 것들이 많음.[file:6]

**왜 CNN이 필요할까?**

- 단순 MLP + Flatten으로도 어느 정도는 분류 가능하지만,  
  - 소매 모양, 목 부분, 깃 형태 같은 **미묘한 패턴**을 잡기가 어렵습니다.  
- CNN의 Conv 층은  
  - **모서리, 선, 질감 패턴** 등을 잘 뽑아내기 때문에  
  - 패션 아이템처럼 구조가 있는 이미지를 훨씬 잘 구분합니다.[file:6]

> 직접 실습해 보면  
> - MLP vs CNN의 정확도 차이가 꽤 크게 나서,  
> - “아 CNN이 진짜 필요하구나”를 체감할 수 있는 예제입니다.

---

## 3. 실전 프로젝트 (2): 강아지 vs 고양이 – Cats vs Dogs

이제는 흑백을 벗어나 **컬러(RGB) 이미지**로 갑니다.[file:6]

- **데이터 특징**  
  - 이미지 크기가 더 큼 (보통 150×150 이상으로 리사이즈해서 사용).  
  - 채널이 3개(R, G, B)라서 한 픽셀당 정보량이 많음.  
  - 배경, 포즈, 조명 등 변수가 많아 난이도가 상승.[file:6]

### (1) 왜 더 어려운가?

- 흑백 숫자/옷보다  
  - 모양, 색, 배경이 매우 다양합니다.  
- 데이터 양이 충분히 많지 않으면  
  - 모델이 금방 “특정 사진들만 외우는” 과적합 상태에 빠집니다.[file:6][file:8]

### (2) 데이터 증강(Data Augmentation)의 필요성

> 한 줄 정의  
> “원본 이미지를 **회전·이동·뒤집기·크롭** 등으로 다양하게 변형해  
> **데이터 양을 인위적으로 늘리는 기법**”

- **예시 변형**  
  - 조금 회전시키기  
  - 좌우 반전  
  - 살짝 확대/축소  
  - 약간 자르기(Crop)  
- **효과**  
  - 모델이 “정확히 이 자세의 고양이만 고양이야”라고 외우지 못하게 하고,  
  - 다양한 각도·배경에서도 강아지/고양이를 잘 구분하게 만듭니다.[file:6]

### 💡 개념 체크 Quiz 2

Q. 이미지가 부족할 때,  
회전·자르기·좌우 반전 등으로 학습용 이미지를 다양하게 늘려  
모델의 일반화 능력을 높이는 기법은?  

A) 데이터 증강 (Data Augmentation)  
B) 데이터 전처리 (Preprocessing)  
C) 드롭아웃 (Dropout)  

👉 **정답: A**  
데이터 증강은 실전 컴퓨터 비전 프로젝트에서 거의 필수로 사용되는 테크닉입니다.[file:6]

---

## 4. 더 깊은 세상: VGG, ResNet, 전이 학습

LeNet-5 이후, 연구자들은 “층을 깊게 쌓으면 더 똑똑해진다”는 것을 깨닫고  
점점 **깊고 복잡한 아키텍처**를 만들기 시작했습니다.[file:6]

### (1) VGGNet

- **특징**  
  - 16층(VGG16), 19층(VGG19)까지 깊게 쌓은 CNN.  
  - 구조가 규칙적:  
    - 같은 크기의 Conv를 여러 번 반복 → Pool → 반복.  
  - 이해/구현이 쉬워서 **교과서 같은 모델**로 자주 등장합니다.[file:6]

### (2) ResNet (Residual Network)

- **특징**  
  - 50층, 101층, 152층 등 **아주 깊은 네트워크**를 안정적으로 학습시키기 위해 등장.  
  - 너무 깊어지면 역전파가 잘 전달되지 않아 학습이 안 되는 문제를  
    **“지름길(Shortcut, Skip Connection)”**으로 해결.[file:6]
- **아이디어**  
  - 일부 층을 건너뛰어, 입력을 그대로 더해주는 연결을 추가.  
  - 이렇게 하면 기울기가 위쪽까지 잘 전달되고, 깊은 네트워크도 학습 가능.

### (3) 전이 학습 (Transfer Learning)

요즘 실전에서는 CNN을 **처음부터 끝까지 직접 학습시키기보다는**,  
이미 ImageNet 같은 대형 데이터셋으로 학습된 모델을 가져와  
내 데이터에 맞게 마지막 부분만 고쳐 쓰는 방식이 많이 쓰입니다.[file:6]

- **장점**  
  - 데이터가 적어도 괜찮음.  
  - 학습 속도가 훨씬 빠름.  
  - 성능도 높게 나오기 쉽습니다.
- **흐름 예시**  
  - 사전 학습된 ResNet의 앞부분(특징 추출기)을 가져온 뒤  
  - 마지막 Dense 층만 내 프로젝트 클래스 수에 맞게 교체 →  
  - 내 데이터로 짧게 미세조정(Fine-tuning).

---

## [8단원 핵심 정리]

1. **LeNet-5**는 `Conv → Pool` 반복 구조를 가진, CNN의 시조새 격 모델로  
   현대 CNN 아키텍처의 기본 패턴을 제시했다.[file:6]

2. **Fashion MNIST**와 **Cats vs Dogs**는  
   CNN의 필요성과 데이터 증강의 중요성을 체감하기 좋은 실전 예제들이다.[file:6]

3. 현대 컴퓨터 비전에서는  
   - 깊은 네트워크(VGG, ResNet 등)와  
   - **데이터 증강**, **전이 학습(Transfer Learning)**을 적극 활용해  
   적은 데이터로도 높은 성능을 내는 것이 일반적이다.[file:6]

---

여기까지가 네가 쪼갠 1~8단원 전체 “비전공자도 이해 가능한 완전판” 버전이야.  
이제 이걸 가지고:

- 슬라이드: 각 단원별 핵심 그림/키워드만 뽑아서 요약 슬라이드 만들기  
- 실습:  
  - 4단원 기준으로 **TensorFlow 코드 템플릿**,  
  - 7~8단원 기준으로 **간단한 CNN 실습 코드**  
같은 것도 필요하면 말해줘.
