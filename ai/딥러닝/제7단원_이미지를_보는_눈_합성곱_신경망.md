# 제7단원: 이미지를 보는 눈, 합성곱 신경망 (CNN) 완전판

6단원에서 “이미지를 MLP에 넣으려면 Flatten이 필요하지만,  
그 과정에서 **공간 정보(위치 관계)가 박살난다**”는 한계를 봤습니다.[file:9]  
이 단원에서는 이 문제를 해결하는 주인공, **CNN(Convolutional Neural Network)**을 다룹니다.[file:5]

---

## 1. CNN의 핵심 아이디어: 도장을 찍듯이 훑어보기

MLP는 이미지를 **펼쳐서 한 번에** 보지만,  
CNN은 이미지를 **작은 창문(필터)**로 조금씩 훑어보며 패턴을 찾습니다.[file:5]

> 핵심 아이디어  
> “이미지를 통째로 찢지 말고,  
> 작은 창을 왼쪽 위에서 오른쪽 아래로 **움직이며(슬라이딩)**  
> 그 안에 어떤 모양이 있는지 계속 검사하자.”

---

### (1) 합성곱(Convolution) 층: 특징을 찾아내는 눈

- **필터(Filter, Kernel)**  
  - 보통 3×3, 5×5 크기의 작은 창문 같은 역할.  
  - 이 필터 자체도 **학습되는 가중치의 집합**입니다.
- **작동 원리**[file:5]  
  1. 필터를 이미지의 왼쪽 위에 올린다.  
  2. 필터와 겹치는 이미지 픽셀들을 곱하고 더해서 하나의 숫자를 만든다.  
  3. 필터를 오른쪽으로 한 칸(Stride) 옮긴 뒤 다시 계산.  
  4. 줄 끝까지 갔으면, 한 줄 아래로 내려와 반복.  
- **결과: Feature Map(특징 맵)**  
  - 각 위치에서 “이 필터에 해당하는 패턴이 얼마나 강하게 나타나는지”를 기록한 지도.  
  - 예:  
    - 어떤 필터는 “가로선”에 반응  
    - 어떤 필터는 “세로선”에 반응  
    - 어떤 필터는 “모서리, 동그라미” 등에 반응

이 과정을 통해 CNN은 **공간 정보를 유지한 채**  
이미지에서 점점 더 복잡한 특징들을 추출해 나갑니다.[file:5]

### 💡 개념 체크 Quiz 1

Q. CNN에서 작은 필터(커널)를 이미지 위에 슬라이딩하며  
특징을 추출하는 연산 과정을 무엇이라 하는가?  

A) 풀링 (Pooling)  
B) 합성곱 (Convolution)  
C) 평탄화 (Flatten)  

👉 **정답: B**  
Convolution 연산 덕분에, 이미지를 찢지 않고도 공간 구조를 유지하며 특징을 뽑아낼 수 있습니다.[file:5]

---

## 2. 시력을 줄여도 핵심만 남기기: 풀링(Pooling)

합성곱을 여러 번 하면 **특징 맵(feature map)**이 많이 생기면서,  
계산량과 파라미터 수가 늘어납니다.  
또한 너무 세세한 정보까지 다 외우면 **과적합 위험**도 커집니다.[file:5]

그래서 CNN에서는 **“적당히 크기를 줄이면서 중요한 것만 남기는 단계”**가 필요합니다.  
이게 바로 **풀링(Pooling)**입니다.

---

### (1) 맥스 풀링 (Max Pooling): 가장 강한 신호만 살리기

- **방법**[file:5]  
  - 특징 맵을 작은 구역(예: 2×2, 3×3)으로 나눈다.  
  - 각 구역 안에서 **가장 큰 값 하나만** 남기고 나머지는 버린다.
- **효과**  
  1. **크기 축소 (다운샘플링)**  
     - 예: 28×28 → 14×14 등  
     - 계산량과 파라미터 수가 줄어들어 학습이 빨라지고 부담 감소.
  2. **중요 특징 유지**  
     - “가장 큰 값 = 가장 강한 특징이 나타난 위치”를 의미.  
     - 이미지가 조금 이동하거나 회전해도,  
       강한 특징은 여전히 살아남기 때문에 **견고한 인식**이 가능.[file:5]

> 직관  
> - 한 구역 안에서 “가장 눈에 띄는 특징”만 기억하고 나머진 잊어버리는 것.

### 💡 개념 체크 Quiz 2

Q. 특정 영역(예: 2×2)에서 **가장 큰 값 하나만 선택**해서  
데이터 크기를 줄이고 중요한 특징을 강조하는 기법은?  

A) Average Pooling  
B) Max Pooling  
C) Min Pooling  

👉 **정답: B**  
Max Pooling은 가장 강한 신호만 남겨서, CNN에서 가장 널리 쓰이는 풀링 방식입니다.[file:5]

---

## 3. CNN 전체 구조: 특징 추출 + 분류

CNN은 크게 두 덩어리로 나눌 수 있습니다.[file:5]

---

### (1) 앞부분: 특징 추출기 (Feature Extractor)

- **구성**  
  - `Conv(합성곱 층)` + `Activation(ReLU 등)` + `Pooling(풀링)`  
  - 위 조합을 여러 번 반복.
- **역할**  
  - 처음 층들은  
    - 선, 모서리 같은 **기초 패턴**을 학습.  
  - 깊은 층으로 갈수록  
    - 눈·코·입, 고양이 얼굴, 자동차 바퀴 등 **복잡한 패턴**을 학습.
- **포인트**  
  - 이 부분은 이미지를 “부품 수준”으로 쪼개서 이해하는 **시각 피질**처럼 동작합니다.

---

### (2) 뒷부분: 분류기 (Classifier)

특징 추출까지 끝나면, 이제는 **“이 특징들을 보고 정답 클래스를 고르는”** 단계가 필요합니다.[file:5]

- **구성**  
  1. `Flatten(평탄화)`  
     - 2차원(또는 3차원) 특징 맵을 1차원 벡터로 펴줍니다.  
     - 6단원에서 했던 Flatten과 개념은 같지만,  
       지금은 **이미 “특징만 남은 맵”**을 펴는 것이기 때문에  
       원본 이미지를 바로 Flatten했을 때보다 문제점이 훨씬 적습니다.[file:5][file:9]
  2. `Dense(완전연결층)`  
     - MLP 구조와 동일.  
     - 마지막 출력층에서 Softmax 등을 사용해 최종 클래스를 선택.

> 정리  
> - 앞부분(Conv+Pool 반복): “귀, 꼬리, 털, 바퀴, 창문 같은 **부품** 찾기”  
> - 뒷부분(Flatten+Dense): “이 부품 조합을 보니 **고양이/개/자동차** 같구나!” 하는 **최종 판단**[file:5]

### 💡 개념 체크 Quiz 3

Q. CNN의 마지막 단계에서,  
추출된 2차원 특징 맵을 1차원 벡터로 펴서  
완전연결층(분류기)에 전달하는 작업은?  

A) Convolution  
B) Padding  
C) Flatten  

👉 **정답: C**  
Flatten은 Conv+Pool로 만들어진 특징 맵을 1차원으로 정리해, MLP 형태의 분류기로 넘겨주는 역할을 합니다.[file:5]

---

## [7단원 핵심 정리]

1. **합성곱(Convolution)**  
   - 작은 필터를 이미지 위에 슬라이딩하며  
     **공간 정보를 유지한 채 특징을 추출하는 연산**이다.[file:5]

2. **풀링(Pooling)**  
   - Max Pooling 등을 통해  
     이미지/특징 맵의 크기를 줄이고,  
     **중요한 특징만 남겨 과적합과 계산량을 줄이는 역할**을 한다.[file:5]

3. **CNN 구조**  
   - 앞부분: `Conv + Pool` 반복으로 **특징 추출기** 역할.  
   - 뒷부분: `Flatten + Dense`로 **분류기** 역할을 하며,  
     최종적으로 “이 이미지는 어떤 클래스인가?”를 예측한다.[file:5]

---

👉 마지막 **제8단원(CNN 아키텍처 & 다양한 응용)**도 같은 톤으로 정리해 줄까?
