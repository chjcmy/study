# 메모리 관리

---

## 메모리 계층 구조

```
속도 빠름 ↑               용량 작음 ↑

 ┌─────────┐
 │레지스터  │  ~1ns    수십~수백 바이트   CPU 내부
 ├─────────┤
 │ L1 캐시  │  ~1ns    32~64 KB         CPU 코어별
 ├─────────┤
 │ L2 캐시  │  ~4ns    256 KB~1 MB      CPU 코어별
 ├─────────┤
 │ L3 캐시  │  ~12ns   수~수십 MB        CPU 공유
 ├─────────┤
 │  RAM    │  ~100ns  수~수백 GB        메인 메모리
 ├─────────┤
 │  SSD    │  ~100μs  수 TB            보조 기억
 ├─────────┤
 │  HDD    │  ~10ms   수 TB            보조 기억
 └─────────┘

속도 느림 ↓               용량 큼 ↓

→ "자주 쓰는 데이터를 빠른 곳에!" = 지역성 원리 (Locality)
```

### 지역성 원리 (Locality)

```
시간적 지역성 (Temporal):
  최근 접근한 데이터를 곧 다시 접근할 확률 높음
  예: 루프 카운터 변수

공간적 지역성 (Spatial):
  접근한 주소 근처를 곧 접근할 확률 높음
  예: 배열 순차 접근

→ 캐시, 페이지 교체 알고리즘의 기본 원리
```

---

## 가상 메모리 (Virtual Memory)

### 개념

```
각 프로세스는 자기만의 연속적인 메모리 공간이 있다고 "착각"

프로세스 A 관점:          프로세스 B 관점:
0x0000 ┌──────┐          0x0000 ┌──────┐
       │ Code │                 │ Code │
       │ Data │                 │ Data │
       │ Heap │                 │ Heap │
       │ ...  │                 │ ...  │
       │Stack │                 │Stack │
0xFFFF └──────┘          0xFFFF └──────┘

실제 물리 메모리:
┌──────┬──────┬──────┬──────┬──────┬──────┐
│ A-코드│B-힙 │ OS  │A-스택│ 빈  │ B-코드│
└──────┴──────┴──────┴──────┴──────┴──────┘

→ MMU(Memory Management Unit)가 가상 → 물리 주소 변환
```

### 가상 메모리의 장점

```
1. 격리: 프로세스간 메모리 간섭 불가 → 보안 + 안정성
2. 추상화: 연속적 메모리 제공 → 프로그래밍 편의
3. 공유: 라이브러리 코드를 여러 프로세스가 공유 (물리적으로 1카피)
4. 스와핑: 물리 메모리보다 큰 프로그램 실행 가능 (디스크 활용)
```

---

## 페이징 (Paging)

### 동작 원리

```
가상 메모리를 고정 크기(보통 4KB) "페이지"로 분할
물리 메모리를 같은 크기의 "프레임"으로 분할

가상 주소    →   페이지 테이블   →   물리 주소
Page 0   (4KB)  →   Frame 5    →   0x5000~0x5FFF
Page 1   (4KB)  →   Frame 2    →   0x2000~0x2FFF
Page 2   (4KB)  →   디스크     →   ⚠️ 페이지 폴트!
Page 3   (4KB)  →   Frame 8    →   0x8000~0x8FFF
```

### 페이지 폴트 (Page Fault) 처리

```
1. CPU가 가상 주소 접근
2. 페이지 테이블에서 해당 페이지가 "디스크"에 있음 확인
3. 페이지 폴트 인터럽트 발생!
4. OS가 디스크에서 해당 페이지를 물리 프레임으로 로드
5. 프레임이 가득 차면? → 페이지 교체 알고리즘으로 희생자 선택
6. 페이지 테이블 업데이트
7. 중단된 명령어 재실행
```

### TLB (Translation Lookaside Buffer)

```
페이지 테이블 조회는 메모리 접근 → 느림!
→ TLB = 페이지 테이블의 캐시

가상 주소 ──→ TLB 확인
              │
          ┌───┴───┐
          │       │
       TLB Hit  TLB Miss
       (빠름)   (느림 → 페이지 테이블 조회 → TLB 갱신)

TLB Hit Rate: 보통 95~99%
→ 메모리 접근 성능에 매우 큰 영향

컨텍스트 스위칭 시:
  프로세스 전환 → TLB 전체 Flush (다른 페이지 테이블!)
  스레드 전환 → TLB 유지 (같은 페이지 테이블)
  → 스레드가 더 빠른 이유 중 하나
```

---

## 페이지 교체 알고리즘

```
물리 메모리 가득 → 새 페이지 로드 시 어떤 페이지를 내보낼까?

1. FIFO (First In First Out)
   가장 먼저 들어온 페이지 제거
   단점: Belady's Anomaly (프레임 늘려도 폴트 증가 가능)

2. LRU (Least Recently Used) ⭐
   가장 오래전에 사용된 페이지 제거
   → 시간적 지역성 기반, 가장 많이 사용
   구현: 카운터 또는 스택
   
3. LFU (Least Frequently Used)
   사용 횟수가 가장 적은 페이지 제거
   
4. Optimal (OPT)
   앞으로 가장 오래 사용 안 될 페이지 제거
   → 이론적 최적, 실제 구현 불가 (미래 예측 필요)
   → 다른 알고리즘의 성능 기준점
```

---

## 스택 vs 힙

```
┌──────────────────────────┐
│         Stack            │  ↓ 아래로 증가
│  - 함수 호출 프레임        │  - 지역 변수, 매개변수, 리턴 주소
│  - 자동 할당/해제          │  - 컴파일 타임에 크기 결정
│  - 빠름 (SP 이동만)       │  - 크기 제한 (보통 1~8MB)
│                          │
│     ↕ (빈 공간)           │
│                          │
│         Heap             │  ↑ 위로 증가
│  - 동적 할당 (malloc/new) │  - 프로그래머가 관리
│  - GC 또는 수동 해제       │  - 런타임에 크기 결정
│  - 느림 (할당 검색)        │  - 크기 유연
└──────────────────────────┘

Python: GC가 힙 메모리 자동 관리 (Reference Counting + Cycle GC)
```

### 스택 오버플로우

```
def infinite_recursion():
    return infinite_recursion()  # 스택 프레임 계속 쌓임!

# RecursionError: maximum recursion depth exceeded
# Python 기본 깊이 제한: 1000

# 해결: 반복문 또는 sys.setrecursionlimit()
```

---

## 면접 핵심 포인트

```
Q: 가상 메모리란?
A: 프로세스에 독립적인 연속 메모리 공간을 제공하는 기법.
   MMU가 가상→물리 주소 변환. 
   격리(보안), 추상화(편의), 스와핑(용량) 제공.

Q: 페이지 폴트란?
A: 접근한 페이지가 물리 메모리에 없을 때 발생.
   OS가 디스크에서 페이지를 로드하고, 필요시 페이지 교체.
   빈번하면 스래싱(Thrashing) 발생 → 성능 급락.

Q: TLB의 역할?
A: 페이지 테이블 캐시. 가상→물리 주소 변환 속도 향상.
   Hit Rate 95%+ → 메모리 접근 성능 핵심.
   프로세스 전환 시 Flush 필요 (스레드는 불필요).

Q: 스택과 힙의 차이?
A: 스택: 자동 관리, 빠름, 크기 제한 (지역 변수)
   힙: 수동/GC 관리, 느림, 유연한 크기 (동적 할당)
```
