# 로그란 무엇인가?

---

## 1. 로그의 정의

**로그(Log)** 란 시스템, 네트워크, 애플리케이션에서 발생하는 **이벤트(사건)를 시간 순서대로 기록한 불변(immutable) 데이터**이다.

핵심 키워드:
- **이벤트**: 상태가 변하는 순간 (요청 수신, 에러 발생, 사용자 로그인 등)
- **시간 순서**: 모든 로그는 타임스탬프를 가진다
- **불변**: 한번 기록되면 수정하지 않는다 (append-only)

---

## 2. 로그의 어원과 역사

### 2.1 항해 일지에서 컴퓨터 로그까지

```
17세기 항해 일지 (Logbook)
└─ 선박의 속도를 측정하기 위해 통나무(log)를 바다에 던진 것에서 유래
   └─ 속도·위치·날씨·사건을 시간 순서대로 기록한 장부

     ↓ (개념 전이)

1960년대 타임셰어링 시스템
└─ 여러 사용자가 한 컴퓨터를 공유 → "누가 언제 접속했는지" 기록 필요
   └─ "login", "logout" 용어가 이 시기에 탄생
      └─ 물리적 출입 기록장부에 서명(sign in)하는 것과 같은 비유

     ↓

1975년 UNIX V6
└─ /etc/utmp (현재 접속 중인 사용자)
   /usr/adm/wtmp (접속 기록 히스토리)
   → 최초의 체계적인 컴퓨터 로그 파일 중 하나

     ↓

1980년대 Syslog 탄생
└─ Eric Allman이 Sendmail 프로젝트를 위해 개발
   └─ UNIX 시스템 전반으로 확산 → 사실상 표준(de facto standard)

     ↓

2001년 RFC 3164 (BSD Syslog)
└─ IETF가 Syslog를 공식 문서화
   └─ 한계: 타임스탬프에 연도·시간대 없음, 자유 형식 메시지

     ↓

2009년 RFC 5424 (현대 Syslog)
└─ RFC 3164를 대체하는 현대적 표준
   └─ ISO 8601 타임스탬프, 구조화 데이터, UTF-8 지원

     ↓

현재: 구조화된 로깅 + 분산 추적
└─ JSON 포맷, OpenTelemetry, 중앙 집중식 수집
```

### 2.2 Syslog의 진화: RFC 3164 → RFC 5424

Syslog는 컴퓨터 로깅의 **근본 프로토콜**이다. 현대 로깅의 많은 개념이 여기서 왔다.

#### RFC 3164 (2001, 구식)

```
<34>Oct 11 22:14:15 mymachine su: 'su root' failed for lonvick on /dev/pts/8
```

| 부분 | 설명 | 문제점 |
|------|------|--------|
| `<34>` | Priority (Facility × 8 + Severity) | 사람이 읽기 어려움 |
| `Oct 11 22:14:15` | 타임스탬프 | ❌ **연도 없음**, 시간대 없음 |
| `mymachine` | 호스트명 | |
| `su:` | 프로그램 이름 (TAG) | 형식 강제 없음 |
| 나머지 | 자유 형식 메시지 (MSG) | ❌ **파싱 불가능** |

#### RFC 5424 (2009, 현대)

```
<34>1 2026-02-24T18:30:00.123+09:00 mymachine su 12345 ID47
  [exampleSDID@32473 iut="3" eventSource="Application" eventID="1011"]
  'su root' failed for lonvick on /dev/pts/8
```

| 부분 | 설명 | 개선점 |
|------|------|--------|
| `<34>1` | Priority + 프로토콜 버전 | 버전 관리 |
| `2026-02-24T18:30:00.123+09:00` | ISO 8601 타임스탬프 | ✅ 연도, 시간대, 밀리초 |
| `mymachine` | 호스트명 | |
| `su` | APP-NAME | ✅ 명확한 필드 분리 |
| `12345` | PROCID (프로세스 ID) | ✅ 새로 추가 |
| `ID47` | MSGID (메시지 유형 ID) | ✅ 새로 추가 |
| `[exampleSDID@...` | **구조화 데이터 (Structured Data)** | ✅ **핵심 혁신**: 키-값 쌍 |
| 나머지 | 메시지 본문 | UTF-8 지원 |

#### Syslog Severity (심각도) 레벨

이것이 바로 **현대 로그 레벨의 기원**이다:

| 숫자 | 이름 | 설명 | 현대 매핑 |
|------|------|------|----------|
| 0 | Emergency | 시스템 사용 불가 | FATAL |
| 1 | Alert | 즉시 조치 필요 | FATAL |
| 2 | Critical | 치명적 조건 | CRITICAL |
| 3 | Error | 에러 조건 | ERROR |
| 4 | Warning | 경고 조건 | WARN |
| 5 | Notice | 정상이지만 중요 | INFO (높음) |
| 6 | Informational | 정보 메시지 | INFO |
| 7 | Debug | 디버그 메시지 | DEBUG |

#### Syslog Facility (시설) 코드

어떤 **종류의 프로그램**이 로그를 보냈는지 구분:

| 숫자 | 시설 | 설명 |
|------|------|------|
| 0 | kern | 커널 메시지 |
| 1 | user | 사용자 레벨 메시지 |
| 2 | mail | 메일 시스템 |
| 3 | daemon | 시스템 데몬 |
| 4 | auth | 인증/보안 메시지 |
| 10 | authpriv | 비공개 인증 메시지 |
| 16~23 | local0~7 | 사용자 정의 용도 |

> 📌 Priority 값 = Facility × 8 + Severity
> 
> 예: `<34>` = Facility 4(auth) × 8 + Severity 2(Critical) = 34
> → "인증 시스템에서 치명적 이벤트 발생"

---

## 3. 로그의 본질적 목적: 6하 원칙

모든 로그의 근본 목적은 하나다: **"무슨 일이 있었는지 나중에 알 수 있게 하는 것"**

```
  When  ─── 언제 일어났는가?     → 타임스탬프
  Where ─── 어디서 일어났는가?    → 호스트명, 서비스명, 파일명
  Who   ─── 누가 발생시켰는가?    → 사용자 ID, 프로세스 ID, IP
  What  ─── 무엇이 일어났는가?    → 이벤트 유형, 상태 변경
  How   ─── 어떻게 일어났는가?    → 요청 파라미터, 입력값
  Why   ─── 왜 일어났는가?       → 에러 메시지, 실패 원인
```

이것을 로그 레코드에 매핑하면:

```json
{
  "when":    "2026-02-24T18:30:00.123+09:00",
  "where":   { "host": "api-server-03", "service": "auth-service", "file": "LoginHandler.java:42" },
  "who":     { "user_id": "U-456", "ip": "203.0.113.42", "process_id": 12345 },
  "what":    "login_failed",
  "how":     { "method": "password", "endpoint": "POST /api/auth/login" },
  "why":     "invalid_password: hash mismatch"
}
```

### 목적별 분류

| 목적 | 설명 | 로그가 없으면? |
|------|------|-------------|
| **관찰 가능성 (Observability)** | 시스템 내부 상태를 외부에서 파악 | 블랙박스 — 안이 안 보임 |
| **문제 해결 (Troubleshooting)** | 장애 원인 추적 및 디버깅 | "왜 안 되는지 모르겠다" |
| **감사 (Auditing)** | 누가 무엇을 했는지 추적 | 책임 소재 불명 |
| **규정 준수 (Compliance)** | 법적·규제적 요구사항 충족 | 벌금·소송 위험 |
| **성능 최적화 (Performance)** | 병목 지점 식별 및 개선 | 감으로 튜닝 |
| **보안 모니터링 (Security)** | 위협 탐지 및 사고 대응 | 공격당해도 모름 |

---

## 4. 로그 레코드의 구조

### 4.1 최소 필수 요소

어떤 형태의 로그든 반드시 포함해야 하는 핵심 요소:

```
┌───────────────────────────────────────────────────────────┐
│                      로그 레코드                             │
│                                                           │
│  ① 타임스탬프 (Timestamp)                                   │
│     └─ 이벤트가 발생한 정확한 시각                               │
│     └─ 형식: ISO 8601 (2026-02-24T18:30:00.123+09:00)      │
│     └─ 왜 중요? 이벤트의 인과관계와 순서를 파악하기 위해              │
│                                                           │
│  ② 심각도 (Severity / Level)                               │
│     └─ 이 이벤트가 얼마나 중요한가                               │
│     └─ 예: ERROR, WARN, INFO, DEBUG                       │
│     └─ 왜 중요? 필터링과 알림 기준                              │
│                                                           │
│  ③ 출처 (Source)                                           │
│     └─ 어디서 발생했는가                                      │
│     └─ 예: 서비스명, 호스트명, 파일명, 함수명                     │
│     └─ 왜 중요? 어디를 봐야 하는지 즉시 파악                      │
│                                                           │
│  ④ 메시지 (Message)                                        │
│     └─ 무엇이 일어났는가에 대한 사람이 읽을 수 있는 설명              │
│     └─ 왜 중요? 개발자가 즉시 이해할 수 있는 맥락 제공               │
└───────────────────────────────────────────────────────────┘
```

### 4.2 확장 요소 (컨텍스트)

현대 시스템에서는 위 4가지만으로는 부족하다. 다음이 추가된다:

```
┌───────────────────────────────────────────────────────────┐
│                    확장 컨텍스트                              │
│                                                           │
│  ⑤ 주체 (Actor / Subject)                                  │
│     └─ user_id, session_id, ip_address                    │
│                                                           │
│  ⑥ 추적 정보 (Tracing)                                      │
│     └─ trace_id: 분산 시스템에서 하나의 요청 흐름을 추적            │
│     └─ span_id: 그 요청 안에서의 개별 작업 단위                  │
│     └─ request_id: 요청 고유 식별자                           │
│     └─ correlation_id: 비즈니스 흐름 전체를 묶는 ID             │
│                                                           │
│  ⑦ 대상 (Target / Resource)                                │
│     └─ 영향받은 리소스 (파일, DB 테이블, API 엔드포인트)            │
│                                                           │
│  ⑧ 결과 (Outcome)                                          │
│     └─ success / failure, HTTP 상태 코드, 에러 타입            │
│                                                           │
│  ⑨ 추가 데이터 (Additional Data)                            │
│     └─ 스택 트레이스, 요청 파라미터, 응답 시간                     │
└───────────────────────────────────────────────────────────┘
```

### 4.3 실제 예시: 좋은 로그 vs 나쁜 로그

#### ❌ 나쁜 로그

```
Error occurred
```

- 언제? 모름
- 어디서? 모름
- 무슨 에러? 모름
- 누가? 모름
- → **아무런 정보도 얻을 수 없다**

#### ❌ 조금 나은 로그

```
2026-02-24 18:30:00 ERROR Failed to process request
```

- 언제: ✅
- 어디서: ❌
- 무슨 에러: ❌ (구체적이지 않음)
- 누가: ❌

#### ✅ 좋은 로그

```json
{
  "timestamp": "2026-02-24T18:30:00.123+09:00",
  "level": "ERROR",
  "service": "order-service",
  "instance": "order-service-pod-3",
  "trace_id": "abc-123-def-456",
  "user_id": "U-789",
  "event": "payment_failed",
  "message": "Payment gateway timeout after 30s",
  "error": {
    "type": "ConnectionTimeoutError",
    "stack": "at PaymentClient.charge(PaymentClient.java:142)..."
  },
  "context": {
    "order_id": "ORD-2026-001",
    "amount": 55000,
    "currency": "KRW",
    "gateway": "stripe",
    "retry_count": 3
  },
  "duration_ms": 30012
}
```

- 언제: ✅ (밀리초 + 시간대까지)
- 어디서: ✅ (서비스, 인스턴스, 코드 위치)
- 무슨 에러: ✅ (타입, 메시지, 스택 트레이스)
- 누가: ✅ (사용자 ID)
- 추적: ✅ (trace_id로 관련 로그 모두 검색 가능)
- 맥락: ✅ (주문번호, 금액, 재시도 횟수)

---

## 5. Observability의 3대 기둥

### 5.1 Observability(관찰 가능성)란?

> **"시스템의 외부 출력만을 관찰하여 내부 상태를 추론할 수 있는 능력"**

원래 제어 이론(Control Theory)에서 온 개념이다:

```
                ┌────────────────┐
  입력 ─────▶  │  시스템 (블랙박스)  │ ─────▶ 출력
                └────────────────┘
                       │
                 내부에서 뭔 일이?
                       │
                       ▼
              ┌──────────────────┐
              │  Observability   │
              │  외부 출력(텔레메트리) │
              │  만으로 내부를 이해  │
              └──────────────────┘
```

모노리식 시스템에서는 로그 파일 하나만 열면 됐다. 하지만 **마이크로서비스**에서는:
- 서비스가 10~100개
- 하나의 요청이 여러 서비스를 거침
- 각 서비스가 독립적으로 배포·스케일링

→ **로그만으로는 전체 그림을 볼 수 없다** → Observability 3대 기둥이 필요

### 5.2 세 기둥의 본질적 차이

```
┌─────────────────────────────────────────────────────────────┐
│                                                             │
│   로그 (Logs)          메트릭 (Metrics)       트레이스 (Traces)  │
│   "무슨 일이 있었다"     "수치가 이렇다"         "경로가 이렇다"       │ 
│                                                             │
│   📝 이산적 이벤트       📊 시계열 숫자          🗺️ 분산 경로         │
│   (Discrete Events)    (Time Series)         (Distributed)  │
│                                                             │
│   개별 중심             집계 중심              요청 중심           │
│   (Each Event)         (Aggregated)          (Per Request)  │
│                                                             │
│   "사용자 A가           "지난 5분간             "이 요청은         │
│    로그인 실패했다"       에러율 5.2%"            A→B→C→DB 순서로  │
│                                                 3.2초 걸렸다" │
└─────────────────────────────────────────────────────────────┘
```

### 5.3 각 기둥 심층 비교

| 관점 | 로그 (Logs) | 메트릭 (Metrics) | 트레이스 (Traces) |
|------|------------|-----------------|------------------|
| **본질** | 개별 이벤트의 상세 기록 | 시간에 따른 숫자 집계 | 요청의 전체 여정 지도 |
| **형태** | 텍스트/JSON (구조화·비구조화) | 숫자 (counter, gauge, histogram) | Span의 트리 구조 |
| **데이터 볼륨** | 🔴 매우 높음 | 🟢 낮음 (집계) | 🟡 중간 (샘플링) |
| **저장 비용** | 🔴 높음 | 🟢 낮음 | 🟡 중간 |
| **검색 속도** | 🟡 인덱스 의존 | 🟢 매우 빠름 | 🟡 중간 |
| **강점** | 원인 분석 (WHY) | 전체 건강도 (WHAT) | 병목 추적 (WHERE) |
| **약점** | 너무 많은 데이터 | "왜"를 알 수 없음 | 설정 노력 필요 |
| **질문에 대답** | "구체적으로 뭐가 실패?" | "전체적으로 괜찮은가?" | "어디서 느려졌는가?" |
| **사용자** | 개발자, 보안팀 | SRE, DevOps | 개발자, SRE |
| **대표 도구** | ELK, Loki, Splunk | Prometheus, Datadog | Jaeger, Zipkin, Tempo |

### 5.4 세 기둥이 함께 작동하는 시나리오

```
사건: 사용자가 주문을 못 하겠다고 신고

━━━ Step 1: 메트릭이 알려준다 ━━━━━━━━━━━━━━━━━━━━━━━━━━

  📊 대시보드에서 확인:
  ┌─────────────────────────────┐
  │  order-service 에러율         │
  │                             │
  │  5% ─                  ╱─   │
  │  4% ─                ╱      │
  │  3% ─              ╱        │
  │  2% ─            ╱          │
  │  1% ─ ──────────╱           │
  │      18:00  18:15  18:30    │
  └─────────────────────────────┘
  → "18:15부터 에러율이 급상승하고 있다!" (WHAT)
  → 하지만 WHY는 모른다

━━━ Step 2: 트레이스가 범위를 좁혀준다 ━━━━━━━━━━━━━━━━━━

  🗺️ 실패한 요청의 트레이스:
  
  ├── API Gateway          [2ms]   ✅
  │   └── Auth Service     [5ms]   ✅
  │       └── Order Service [15ms] ✅
  │           └── Payment Service [30,012ms] ❌ TIMEOUT
  │               └── Stripe API  [---]  ❌ 응답 없음

  → "Payment Service가 Stripe API 호출에서 타임아웃 발생!" (WHERE)
  → 하지만 구체적 원인은 아직 모른다

━━━ Step 3: 로그가 원인을 밝혀준다 ━━━━━━━━━━━━━━━━━━━━━

  📝 Payment Service 로그 (trace_id로 필터링):

  18:30:00.001 INFO  Initiating payment for order ORD-2026-001
  18:30:00.005 INFO  Connecting to Stripe API (endpoint: api.stripe.com)
  18:30:00.010 WARN  Stripe API slow response (5s elapsed)
  18:30:15.000 WARN  Stripe API retry #1 failed (15s elapsed)
  18:30:25.000 WARN  Stripe API retry #2 failed (25s elapsed)
  18:30:30.012 ERROR ConnectionTimeoutError: Stripe API unreachable
                     after 30s, 3 retries exhausted
                     Root cause: DNS resolution failure for api.stripe.com
                     DNS server 10.0.0.53 not responding

  → "DNS 서버가 응답하지 않아서 Stripe에 연결 못 함!" (WHY)
  → 해결: DNS 서버 확인 또는 fallback DNS 설정
```

### 5.5 OpenTelemetry: 3대 기둥의 통합

**OpenTelemetry (OTel)** 는 CNCF(Cloud Native Computing Foundation) 프로젝트로, 세 기둥을 **하나의 통합 프레임워크**로 수집한다.

```
                        애플리케이션 코드
                             │
                    OpenTelemetry SDK
                     (계측 라이브러리)
                             │
                ┌────────────┼────────────┐
                │            │            │
             Traces       Metrics       Logs
                │            │            │
                └────────────┼────────────┘
                             │
                      OTLP (표준 프로토콜)
                             │
                   OTel Collector
                   (수집·처리·라우팅)
                             │
                ┌────────────┼────────────┐
                │            │            │
             Jaeger     Prometheus    Elasticsearch
             Tempo      Datadog       Loki
             Zipkin     Grafana       Splunk
```

**핵심 혁신: Context Propagation (컨텍스트 전파)**

```
요청이 서비스를 거칠 때마다 동일한 trace_id가 전파된다:

  Client → [trace_id: abc-123] → Service A
                                     │
                                     └─ [trace_id: abc-123] → Service B
                                                                  │
                                                                  └─ [trace_id: abc-123] → DB

이 trace_id가 로그에도, 메트릭에도, 트레이스에도 들어간다
→ abc-123으로 검색하면 세 기둥의 모든 관련 데이터를 한 번에 볼 수 있다
```

이것이 바로 **상관관계(Correlation)** 의 핵심이다:
- 로그에서 `trace_id=abc-123` 검색 → 관련 로그만 필터링
- 트레이스에서 `abc-123` 조회 → 전체 요청 경로 시각화
- 메트릭에서 해당 시간대 확인 → 더 넓은 맥락 파악

---

## 6. 로그를 보는 관점의 차이

같은 로그라도 **누가 보느냐**에 따라 다른 가치를 갖는다:

| 역할 | 로그에서 보는 것 | 핵심 관심사 |
|------|---------------|-----------|
| **개발자** | 에러 로그, 스택 트레이스, 디버그 로그 | "왜 버그가 생겼는가?" |
| **SRE/DevOps** | 성능 로그, 가용성 로그, 메트릭 | "시스템이 안정적인가?" |
| **보안팀** | 인증 로그, 접근 제어 로그 | "누가 침입을 시도했는가?" |
| **감사/규정준수** | 감사 로그, 데이터 접근 로그 | "규정을 준수하고 있는가?" |
| **비즈니스/기획** | 사용자 행동 로그, 트랜잭션 로그 | "사용자가 어떻게 서비스를 쓰는가?" |
| **경영진** | 대시보드 (메트릭 기반) | "서비스가 돈을 벌고 있는가?" |

---

## 정리

```
로그란?
├── 정의: 이벤트를 시간 순서대로 기록한 불변 데이터
├── 역사: 항해 일지 → UNIX → Syslog → RFC 5424 → 구조화 로깅
├── 목적: 6하 원칙 (When, Where, Who, What, How, Why)
├── 구조: 타임스탬프 + 심각도 + 출처 + 메시지 + 컨텍스트
├── 위치: Observability 3대 기둥 중 하나 (Logs, Metrics, Traces)
└── 통합: OpenTelemetry로 세 기둥을 하나의 trace_id로 연결
```
