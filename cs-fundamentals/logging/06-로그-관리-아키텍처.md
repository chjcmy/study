# 로그 관리 아키텍처 (Log Management Architecture)

---

## 1. 왜 중앙 집중식 로깅이 필요한가?

### 1.1 분산 시스템의 현실

```
마이크로서비스 환경:

  ┌──────────┐  ┌──────────┐  ┌──────────┐
  │ API GW   │  │ Auth     │  │ Order    │
  │ Pod ×3   │  │ Pod ×2   │  │ Pod ×5   │
  └──────────┘  └──────────┘  └──────────┘
  ┌──────────┐  ┌──────────┐  ┌──────────┐
  │ Payment  │  │ Inventory│  │ Notify   │
  │ Pod ×3   │  │ Pod ×2   │  │ Pod ×2   │
  └──────────┘  └──────────┘  └──────────┘

  6개 서비스 × 평균 3 인스턴스 = 17개의 로그 소스
  Kubernetes에서는 Pod이 수시로 생성/삭제됨
  
  만약 각 서버에 SSH로 들어가서 로그를 확인하면?
  → 17개 터미널을 동시에 열어야 함
  → Pod이 재시작되면 로그가 사라짐
  → 서비스 간 요청 추적에 수십 분 소요
```

**중앙 집중식 로깅이 해결하는 것:**

```
  ┌──────────────────────────────────────┐
  │         중앙 로그 시스템               │
  │                                       │
  │  모든 서비스의 로그가 한 곳에           │
  │  → trace_id로 전체 흐름 추적           │
  │  → 실시간 검색, 대시보드, 알림          │
  │  → Pod이 죽어도 로그는 영구 보존        │
  └──────────────────────────────────────┘
```

---

## 2. 로그 파이프라인: 5단계 아키텍처

모든 로그 관리 시스템은 이 5단계를 거친다:

```
┌────────┐   ┌────────┐   ┌────────┐   ┌────────┐   ┌────────┐
│ ① 생성  │──▶│ ② 수집  │──▶│ ③ 처리  │──▶│ ④ 저장  │──▶│ ⑤ 분석  │
│ Produce │   │ Collect │   │ Process │   │ Store  │   │ Analyze│
└────────┘   └────────┘   └────────┘   └────────┘   └────────┘
  앱/서버       에이전트      변환/필터      DB/스토리지    시각화/알림
```

### 2.1 ① 생성 (Produce)

애플리케이션, OS, 네트워크 장비, 클라우드 서비스에서 로그 생성.

```
생성 소스:
  ├── 애플리케이션: logger.info(), console.log()
  ├── 웹 서버: Nginx access.log, error.log
  ├── OS: syslog, journald, Windows Event Log
  ├── 컨테이너: stdout/stderr → Docker/K8s가 수집
  ├── 데이터베이스: slow query log, audit log
  ├── 네트워크: 방화벽 로그, DNS 쿼리
  └── 클라우드: AWS CloudTrail, Azure Activity Log
```

### 2.2 ② 수집 (Collect)

**에이전트(Agent)** 가 로그를 모아서 중앙으로 전송.

```
수집 에이전트의 역할:

  ┌─────────────────────────────────────────┐
  │  서버 / Pod                               │
  │                                           │
  │  [앱] → stdout → [컨테이너 런타임]          │
  │                         │                  │
  │                 /var/log/containers/*.log   │
  │                         │                  │
  │                  ┌──────┴──────┐            │
  │                  │  수집 에이전트  │            │
  │                  │ (Fluent Bit,  │            │
  │                  │  Filebeat 등) │            │
  │                  └──────┬──────┘            │
  └─────────────────────────┼──────────────────┘
                            │ (TLS 암호화)
                            ▼
                    중앙 수집 서버
```

### 2.3 ③ 처리 (Process)

수집된 로그를 **변환, 필터링, 정규화, 보강(enrichment)** 한다.

```
처리 파이프라인:

  입력 (raw log)
    │
    ├── 파싱: 비구조화 → 구조화 (JSON)
    │   └─ 예: Nginx 로그 → JSON 필드 분리
    │
    ├── 정규화: 필드명 통일
    │   └─ 예: "ts", "timestamp", "time" → 모두 "@timestamp"
    │
    ├── 필터링: 불필요한 로그 제거
    │   └─ 예: 헬스 체크 /health 요청 제거
    │
    ├── 보강: 추가 정보 붙이기
    │   └─ 예: IP → 위치 정보 (GeoIP), 호스트 메타데이터
    │
    ├── 마스킹: 민감 정보 제거
    │   └─ 예: 카드번호 마스킹, 비밀번호 삭제
    │
    └── 라우팅: 목적지별 분배
        └─ 예: 에러 → ES + 알림, 디버그 → S3만
```

### 2.4 ④ 저장 (Store)

처리된 로그를 검색·분석이 가능한 저장소에 보관.

| 저장소 유형 | 예시 | 장점 | 단점 |
|-----------|------|------|------|
| **검색 엔진** | Elasticsearch | 빠른 풀텍스트 검색, 실시간 | 비용 높음, 운영 복잡 |
| **로그 전용 DB** | Grafana Loki | 비용 효율 (라벨만 인덱싱) | 풀텍스트 검색 불가 |
| **오브젝트 스토리지** | S3, Azure Blob | 매우 저렴, 무제한 | 검색 느림 |
| **시계열 DB** | ClickHouse | 집계 쿼리 빠름 | 풀텍스트 검색 약함 |

### 2.5 ⑤ 분석 (Analyze)

저장된 로그를 검색, 시각화, 알림으로 가치를 만든다.

```
분석 활동:

  실시간 모니터링
  ├── 대시보드: 에러율, 응답 시간, 요청량 시각화
  └── 알림: 에러율 5% 초과 시 Slack 알림

  사후 분석
  ├── 검색: "왜 사용자 U-456의 주문이 실패했는가?"
  ├── 트렌드: "최근 1주일간 에러 증가 추세"
  └── 포렌식: "3개월 전 공격자의 행동 추적"
```

---

## 3. 수집 에이전트 비교

### 3.1 전체 비교

| | Fluent Bit | Fluentd | Logstash | Vector | Filebeat |
|---|-----------|---------|----------|--------|----------|
| **언어** | C | Ruby+C | Java (JRuby) | Rust | Go |
| **메모리** | ~1MB | ~40MB | ~200MB+ | ~10MB | ~10MB |
| **용도** | 경량 수집 | 유연한 수집·변환 | 고급 처리·변환 | 고성능 수집·변환 | 경량 수집 (Elastic) |
| **플러그인** | ~100개 | ~800개 | ~200개 | ~100개 | 제한적 |
| **K8s 적합성** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ |
| **처리 능력** | 기본 | 중급 | 고급 | 고급 | 기본 |
| **생태계** | CNCF | CNCF | Elastic | Datadog | Elastic |

### 3.2 어떤 것을 선택할 것인가?

```
선택 의사결정 트리:

  Kubernetes 환경인가?
     │
     ├── YES ─── 리소스가 매우 제한적인가?
     │              │
     │              ├── YES → Fluent Bit (1MB 메모리)
     │              │
     │              └── NO ─── 고급 변환이 필요한가?
     │                            │
     │                            ├── YES → Vector (Rust, 고성능) 또는 Fluentd
     │                            │
     │                            └── NO → Fluent Bit
     │
     └── NO ─── Elastic 스택을 이미 사용 중인가?
                   │
                   ├── YES → Filebeat (경량) 또는 Logstash (고급 처리)
                   │
                   └── NO → Vector (벤더 중립) 또는 Fluentd (풍부한 플러그인)
```

### 3.3 일반적인 조합 패턴

```
패턴 1: 에이전트 + 어그리게이터 (2단계)

  ┌─ 노드 1 ─┐  ┌─ 노드 2 ─┐  ┌─ 노드 3 ─┐
  │ Fluent Bit│  │ Fluent Bit│  │ Fluent Bit│   경량 에이전트
  └─────┬─────┘  └─────┬─────┘  └─────┬─────┘   (각 노드)
        │              │              │
        └──────────────┼──────────────┘
                       │
                ┌──────┴──────┐
                │  Fluentd     │                   중앙 어그리게이터
                │  (aggregator)│                   (변환, 라우팅)
                └──────┬──────┘
                       │
         ┌─────────────┼─────────────┐
         ▼             ▼             ▼
    Elasticsearch    S3/Glacier     Kafka
    (Hot 검색)       (Cold 보관)    (스트리밍)


패턴 2: 에이전트 → 버퍼 → 다중 목적지

  Fluent Bit → Kafka (버퍼) → Consumer A → Elasticsearch
                             → Consumer B → S3
                             → Consumer C → SIEM
```

---

## 4. 3大 로그 스택 비교

### 4.1 ELK Stack

```
E = Elasticsearch (저장·검색)
L = Logstash (수집·처리)         → 현대에는 Beats/Fluent Bit로 대체 추세
K = Kibana (시각화)

  ┌──────────┐     ┌──────────┐     ┌──────────────┐     ┌──────────┐
  │ Filebeat │────▶│ Logstash │────▶│ Elasticsearch│────▶│  Kibana  │
  │ (수집)   │     │ (처리)   │     │ (저장·검색)    │     │ (시각화) │
  └──────────┘     └──────────┘     └──────────────┘     └──────────┘
```

**장점:**
- 풀텍스트 검색 최강 — 로그 내용 어디든 검색 가능
- 풍부한 분석 기능 — 집계, 히스토그램, 상관 분석
- 성숙한 생태계 — 10년 이상의 역사, 방대한 커뮤니티
- Kibana의 강력한 시각화

**단점:**
- 💰 비용 높음 — 모든 로그를 인덱싱하므로 저장·메모리 비용 큼
- 🔧 운영 복잡 — 클러스터 관리, 샤드 관리, 용량 계획 필요
- 📈 스케일링에 전문 지식 필요

**적합한 환경:** 풀텍스트 검색이 중요한 환경, 보안 분석, 대규모 엔터프라이즈

### 4.2 EFK Stack

```
E = Elasticsearch
F = Fluentd 또는 Fluent Bit       → Logstash 대비 경량, K8s 친화적
K = Kibana

  ┌────────────┐     ┌──────────────┐     ┌──────────┐
  │ Fluent Bit │────▶│ Elasticsearch│────▶│  Kibana  │
  │ (DaemonSet)│     │              │     │          │
  └────────────┘     └──────────────┘     └──────────┘
```

**ELK와의 차이:**
- Logstash(Java, ~200MB) → Fluent Bit(C, ~1MB) 교체
- Kubernetes DaemonSet으로 각 노드에 자동 배포
- Pod의 stdout/stderr를 자동 수집

**적합한 환경:** Kubernetes 기반 마이크로서비스, 클라우드 네이티브

### 4.3 Grafana Loki Stack (PLG)

```
P = Promtail (수집)
L = Loki (저장·검색)
G = Grafana (시각화)

  ┌──────────┐     ┌──────────┐     ┌──────────┐
  │ Promtail │────▶│   Loki   │────▶│ Grafana  │
  │ (수집)   │     │ (저장)   │     │ (시각화) │
  └──────────┘     └──────────┘     └──────────┘
```

**Loki의 혁신적 접근: 라벨만 인덱싱**

```
  Elasticsearch:                    Loki:
  ┌─────────────────────┐          ┌─────────────────────┐
  │ 모든 필드를 인덱싱     │          │ 라벨만 인덱싱          │
  │                      │          │                      │
  │ "payment failed      │          │ {service="payment",  │
  │  for order ORD-123   │ → 전체   │  env="prod",         │ → 라벨만
  │  amount=50000        │   인덱싱  │  level="error"}      │   인덱싱
  │  gateway=stripe"     │          │                      │
  │                      │          │ 로그 내용은 압축        │
  │ 저장: 💰💰💰          │          │ 저장만 하고 인덱싱 안 함  │
  └─────────────────────┘          │                      │
                                   │ 저장: 💰              │
                                   └─────────────────────┘
```

**장점:**
- 💰 비용 대폭 절감 — S3/GCS에 압축 저장, 인덱싱 최소화
- 🚀 설치·운영 간단 — Elasticsearch 대비 훨씬 가벼움
- 📊 Grafana와 네이티브 통합 — 메트릭(Prometheus)과 로그를 한 대시보드에
- 🏷️ Kubernetes 라벨과 자연스럽게 연동

**단점:**
- ❌ 풀텍스트 검색 불가 — 로그 내용을 검색하려면 라벨로 범위를 먼저 좁혀야 함
- ⏱️ 대량 검색 시 느림 — 인덱싱 없이 압축 데이터를 스캔하므로
- 🔍 복잡한 분석 쿼리 제한적

**적합한 환경:** 비용에 민감한 환경, Prometheus를 이미 사용 중, K8s 네이티브

### 스택 선택 가이드

```
예산이 넉넉하고 풀텍스트 검색이 중요한가?
   │
   ├── YES → ELK/EFK Stack
   │
   └── NO ─── 이미 Prometheus + Grafana를 쓰고 있는가?
                 │
                 ├── YES → Loki (PLG Stack)
                 │
                 └── NO ─── 팀의 운영 역량이 충분한가?
                               │
                               ├── YES → ELK/EFK
                               │
                               └── NO → Loki (운영 부담 적음)
```

---

## 5. SIEM: 보안 특화 로그 관리

### 5.1 SIEM이란?

**SIEM (Security Information and Event Management)** 은 보안 로그를 수집·상관분석·알림하는 보안 특화 플랫폼이다.

```
로그 관리 시스템 vs SIEM:

  로그 관리 시스템 (ELK 등)          SIEM (Splunk, Sentinel 등)
  ┌────────────────────────┐      ┌────────────────────────────┐
  │ 수집, 저장, 검색, 시각화   │      │ 수집, 저장, 검색, 시각화      │
  │                         │      │ + 위협 탐지 규칙               │
  │                         │      │ + 상관관계 분석                │
  │                         │      │ + 행위 분석 (UEBA)            │
  │                         │      │ + 위협 인텔리전스 연동          │
  │                         │      │ + 자동 대응 (SOAR)            │
  │                         │      │ + 규정 준수 보고서              │
  └────────────────────────┘      └────────────────────────────┘
         범용                              보안 특화
```

### 5.2 SIEM의 핵심 기능: 상관관계 분석

```
개별 이벤트만 보면:

  18:00  로그인 실패 (user: admin)         → 흔한 이벤트
  18:01  로그인 실패 (user: admin)         → 또 실패했네
  18:02  로그인 실패 (user: admin)         → 비밀번호 잊었나?
  18:03  로그인 성공 (user: admin)         → 기억해냈구나
  18:04  권한 변경 (admin → superadmin)    → 업무인가?
  18:05  전체 DB 다운로드 시작              → 백업인가?

  → 개별로 보면 각각 정상 또는 경미한 이벤트

SIEM의 상관관계 분석:

  ┌──────────────────────────────────────────────────────────┐
  │  탐지 규칙: "무차별 대입 → 권한 상승 → 데이터 유출"        │
  │                                                           │
  │  18:00~18:02  3회 로그인 실패 (동일 계정)                  │
  │  18:03        로그인 성공                                  │──▶ 🚨 HIGH ALERT
  │  18:04        권한 상승 (admin → superadmin)               │    "계정 탈취 + 데이터
  │  18:05        대량 데이터 다운로드                           │     유출 의심!"
  │                                                           │
  │  → 5개 이벤트를 연결하면 = 공격 캠페인!                     │
  └──────────────────────────────────────────────────────────┘
```

### 5.3 탐지 규칙 예시

```yaml
# SIEM 탐지 규칙 (의사 코드)

rule: brute_force_then_escalation
  description: "무차별 대입 후 권한 상승 탐지"
  severity: HIGH
  
  sequence:
    - event: login_failed
      count: >= 5
      within: 10 minutes
      group_by: user_id
    
    - event: login_success
      same: user_id
      within: 5 minutes
    
    - event: privilege_change
      same: user_id
      within: 30 minutes
  
  action:
    - alert: SOC team via PagerDuty
    - auto_response: disable account temporarily
    - enrich: add geo_ip, threat_intel lookup
```

### 5.4 주요 SIEM 제품 비교

| | Splunk | Microsoft Sentinel | Elastic SIEM | 오픈소스 (Wazuh) |
|---|-------|------------------|-------------|----------------|
| **배포** | 온프레미스/SaaS | Azure 클라우드 | 자체 호스팅/클라우드 | 자체 호스팅 |
| **비용 모델** | 데이터 볼륨 기반 | 데이터 수집량 기반 | 노드 기반 (유료) / 무료 | 무료 |
| **강점** | 성숙한 생태계, SPL 쿼리 | Azure 통합, AI, SOAR | ELK 기반, 유연 | 무료, 침입 탐지 |
| **SOAR** | Splunk SOAR | Logic Apps 연동 | 제한적 | 기본 |
| **학습 곡선** | 높음 | 중간 | 중간 | 중간~높음 |
| **적합 대상** | 대기업, 고급 분석 | Azure 사용 조직 | ELK 기존 사용자 | 예산 제한 조직 |

### 5.5 SOC (Security Operations Center) 워크플로우

```
━━━ SOC에서 SIEM이 작동하는 흐름 ━━━━━━━━━━━━━━━━━━━━━

  ① 데이터 수집
  │  방화벽, IDS, 서버, 앱, 클라우드 → SIEM으로 로그 전송
  │
  ② 정규화 & 상관분석
  │  SIEM이 수천 개의 이벤트를 상관 규칙으로 분석
  │  → 의미 있는 "인시던트"로 집약
  │
  ③ 알림 생성 (Tier 1 분석가)
  │  SIEM이 알림을 생성 → SOC 대시보드에 표시
  │  Tier 1 분석가가 초기 분류 (Triage):
  │  └─ 오탐(False Positive)? → 규칙 튜닝
  │  └─ 진짜 위협? → Tier 2로 에스컬레이션
  │
  ④ 조사 (Tier 2 분석가)
  │  SIEM에서 관련 로그 전체를 검색
  │  공격 범위, 영향, 타임라인 파악
  │  위협 인텔리전스와 대조
  │
  ⑤ 대응 (Tier 3 / IR 팀)
  │  격리, 차단, 복구, 포렌식
  │  SOAR로 자동 대응 (IP 차단, 계정 비활성화)
  │
  ⑥ 사후 분석
  │  근본 원인 분석, 재발 방지
  │  탐지 규칙 개선, 보고서 작성
  │
  ⑦ 지속적 개선
     MITRE ATT&CK 매핑으로 탐지 커버리지 확인
     새로운 위협에 대한 규칙 추가
```

---

## 6. 실전 아키텍처 패턴

### 6.1 소규모 팀 (서비스 1~5개)

```
  앱 → stdout → Fluent Bit → Loki → Grafana

  비용: 거의 무료 (셀프 호스팅)
  운영 부담: 낮음
  적합: 스타트업, 사이드 프로젝트
```

### 6.2 중규모 팀 (서비스 5~30개)

```
  앱 → stdout → Fluent Bit → Kafka → Logstash → Elasticsearch → Kibana
                              │
                              └──→ S3 (장기 보관)

  비용: 중간
  운영 부담: 중간 (Kafka + ES 운영)
  적합: 성장하는 스타트업, 중소기업
```

### 6.3 대규모 조직 (서비스 30개+)

```
  앱 → stdout → Fluent Bit (DaemonSet)
                     │
                 Kafka (버퍼 + 디커플링)
                     │
         ┌───────────┼───────────┐
         ▼           ▼           ▼
    Elasticsearch   Loki        SIEM
    (운영 분석)    (비용 효율)   (보안 분석)
         │           │           │
      Kibana      Grafana     SOC 대시보드
         │
     S3 Glacier
     (장기 아카이브)

  비용: 높음
  운영 부담: 높음 (전담 팀 필요)
  적합: 대기업, 규제 산업
```

---

## 정리

```
로그 관리 아키텍처:
│
├── 중앙 집중식 로깅: 분산 시스템에서 필수
│
├── 5단계 파이프라인:
│   ① 생성 (앱/OS/네트워크)
│   ② 수집 (에이전트: Fluent Bit, Filebeat, Vector)
│   ③ 처리 (파싱, 정규화, 필터링, 마스킹, 라우팅)
│   ④ 저장 (ES, Loki, S3, ClickHouse)
│   ⑤ 분석 (대시보드, 검색, 알림)
│
├── 에이전트 비교:
│   ├── Fluent Bit: 1MB, K8s 최적, CNCF
│   ├── Fluentd: 40MB, 800+ 플러그인, CNCF
│   ├── Logstash: 200MB+, 고급 처리, Elastic
│   ├── Vector: 10MB, Rust 고성능, 벤더 중립
│   └── Filebeat: 10MB, 경량, Elastic 전용
│
├── 3大 로그 스택:
│   ├── ELK: 풀텍스트 검색 최강, 비용 높음
│   ├── EFK: ELK + K8s 최적화 (Fluent Bit)
│   └── PLG (Loki): 라벨만 인덱싱, 비용 획기적 절감
│
├── SIEM:
│   ├── 핵심: 상관관계 분석 (개별 이벤트 → 공격 탐지)
│   ├── 제품: Splunk, Sentinel, Elastic SIEM, Wazuh
│   └── SOC: 7단계 워크플로우 (수집→분석→알림→조사→대응→사후→개선)
│
└── 규모별 패턴:
    ├── 소규모: Fluent Bit → Loki → Grafana
    ├── 중규모: Fluent Bit → Kafka → ES → Kibana
    └── 대규모: Fluent Bit → Kafka → ES + Loki + SIEM
```
